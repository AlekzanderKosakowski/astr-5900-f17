{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7\n",
    "\n",
    "## ASTR 5900, Fall 2017, University of Oklahoma\n",
    "\n",
    "### KMeans and KDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "### Part A\n",
    "\n",
    "Load the Old Faithful data from http://www.stat.cmu.edu/~larry/all-of-statistics/=data/faithful.dat.  \n",
    "\n",
    "A standard procedure in problems with multi-dimensional data is to standardize the data, or give each dimension the same scaling.  It is common to make every parameter distributed around 0 with a standard variance.  That is, find a new data set with parameters $y_{i}^{(j)}$ where:\n",
    "\n",
    "$$ y_{i}^{(j)} = \\frac{x_{i}^{(j)} - \\mu^{(j)}}{\\sigma^{(j)}}$$\n",
    "\n",
    "Here $x_{i}^{(j)}$ is the $i$th data point in the $j$th dimension.\n",
    "\n",
    "Transform the Old Faithful Data in this manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Use `sklearn.cluster.KMeans` to split the Old Faithful data into 2 clusters.  Plot the data with each point colored according to its cluster label.  Also plot the centers of the clusters by making it distinguishable from the data.\n",
    "\n",
    "Read more at http://scikit-learn.org/stable/modules/density.html.  Consider looking at the examples on the `scikit-learn` website and the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "Code from scratch (that is, with default python and numpy) your own k-means clustering algorithm to split the data into 2 clusters.  Refer to the lecture and Figure 9.1 in Bishop.  Plot the end result as you did in Part B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 2\n",
    "\n",
    "In this problem you will perform kernel density estimation to produce\n",
    "an optimal representation of the Chandra X-ray observatory data from\n",
    "NGC 4636.  The X-ray emission traces the emission of hot gas in the galaxy.\n",
    "The data consist of a list of the positions of individual\n",
    "photons on the detector in sky coordinates.\n",
    "\n",
    "### Part A\n",
    "\n",
    "Load the data of NGC 4636 from `ngc4636.dat`.\n",
    "\n",
    "Create a plot showing the individual photon points using `matplotlib.pyplot`.\n",
    "\n",
    "Plot a histogram of the data.  Experiment with the binsize and plot representation until you obtain a pleasing image of the galaxy.  Do you see any structure in the image\n",
    "besides the central concentration of hot gas?  Explain.\n",
    "\n",
    "Perform KDE data using `sklearn.neighbors.kde.KernelDensity`.  Experiment with the \n",
    "band width and kernel until you obtain a pleasing image of the galaxy.  Do you see any \n",
    "structure in the image besides the central concentration of hot gas?  Explain.\n",
    "Note that KernelDensity.score_samples returns the log of the distribution.\n",
    "Also note that it may help for plotting the image to sample the distribution on a grid;\n",
    "refer to the example shown in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "What is the optimal bandwidth to replicate the structure of the data?  One way to determine this value is to maximize the 'leave-one-out likelihood cross-validation' function:\n",
    "\n",
    "$$ \\text{CV}_l \\, (h) = \\frac{1}{N} \\sum_{i=1}^{N} \\log \\hat{f}_{h, -i}(x_i)$$\n",
    "\n",
    "where $\\hat{f}_{h, -i}(x_i)$ is the estimated density at position $x_i$ with the $i$th data point left out and bandwith $h$.  Refer to the lecture.\n",
    "\n",
    "You will want to create a 1D grid of 20 different values of h to test.  Examining the results\n",
    "of part A, what do you think the minimum binsize should be?  Explain.  What do you think\n",
    "the maximum binsize should be?  Explain.\n",
    "\n",
    "In short, approximate the optimal bin size by finding the bin size (among a \"good\" sample of widths) that maximizes $CV_l$.\n",
    "\n",
    "**NOTE: This calculation could take several minutes.  To test your code, you may wish to only consider a fraction of the galaxy data with only a few kernel widths.**\n",
    "\n",
    "At the end of the day:\n",
    "1. Print your optimal $h$  \n",
    "2. Plot $CV_l$ versus the your $h$ samples (perhaps $\\log h$)\n",
    "3. Plot the estimated density of the galaxy using the optimal $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
