{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\n",
    "\n",
    "## ASTR 5900, Fall 2017, University of Oklahoma\n",
    "\n",
    "### MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "We are going to use the `emcee` package to estimate the parameters of our emission data given a double Gaussian plus background model as in HW4 Problem 1.B.  `emcee` uses affine invariant MCMC walkers to approximate distributions (http://dfm.io/emcee/current/).  Doing this problem requires a working knowledge of `emcee`.\n",
    "\n",
    "### Part A\n",
    "\n",
    "Load the data from `emission-line.dat`.\n",
    "\n",
    "Before we can sample our distribution using MCMC, we must define it.  This week we will be defining our loglikelihood as a $\\chi^2$: $$  \\ln p(data | \\vec{\\theta})  = -\\frac{1}{2}\\sum_i \\left(  \\frac{y_{\\text{model}}(x_i) - y_i}{\\sigma_i}\\right)^2  $$\n",
    "As in HW4, we may assume that the error of each data point is the same (0.05).  In this case, the actual numerical value doesn't actually matter. (Do you know why?)\n",
    "\n",
    "Define python functions for the log-prior, log-likelihood, and log-posterior.  If you use uniform priors for the parameters, you must have the log-prior function return a highly negative value if a paramter is out of your defined range.  I suggest returning `-np.inf`; read http://dfm.io/emcee/current/user/faq/#parameter-limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Load the `emcee` package.\n",
    "\n",
    "Remember the goal for this problem: to sample our log-posterior for all 7 parameters because doing so exactly is too computationally expensive.  We will use an `emcee.EnsembleSampler` object to sample our space.  `EnsembleSampler` objects need certain information at instantiation: number of dimensions our walkers will travel through, number of walkers, and the function they are sampling (our log-posterior).  The samplers also take certain keyword arguments, such as a list of additional arguments passed to the log-posterior function.\n",
    "Consider reading the docs (https://media.readthedocs.org/pdf/emcee/stable/emcee.pdf#page=29).  The website linked above also contains information.\n",
    "\n",
    "For this part, define the number of dimensions and number of walkers.  Instantiate an `EnsembleSampler` object (by assigning it to a variable).  Run the sampler by calling its `run_mcmc` method which needs two arguments: the initial positions of the walkers and the number of steps.  Make sure the initial positions of the walkers are within the allowed bounds as defined by the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "Plot the acceptance fraction of each walker.  Also plot the evolution of the walkers, which is accessed va `EnsembleSampler.chain`.  You may notice the distribution of walkers is very thin at the beginning of the evolution; we only want to consider a 'burnt-in' chain otherwise our results will be biased towards the initial positions of the walkers.  Remove the part of the chain before where the walkers are burnt-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D \n",
    "\n",
    "Using `EnsembleSampler.chain`, find a point estimate  and 95% credible region for each of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E\n",
    "\n",
    "Which 2 parameters do you think would have the highest covariance?  Least?  Why?  Discuss, then plot the joint-distributions of both pairs of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was your answer affirmed?  If you got results you didn't expect, discuss why might the parameters be correlated/uncorrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "Consider a 2D lattice of size $L \\times L$.  In this model, we want to randomly assign a value of 0 or 1 to each of the lattice sites in such a way that no two adjacent vertices both take the value of 1 (two lattice sites are adjacent if they share an edge).  A configuration that meets this condition is known as *feasible*.  For now we will pick random configurations such that each feasible configuration has an equal probability, while infeasible configurations have a probability of precisely 0.  One might ask,what is the expected number of 1's in our grid?  That is: \n",
    "\n",
    "$$ E \\left[ n(X)\\right]  = \\sum_{\\xi} n(\\xi) P(\\xi)$$\n",
    "where $\\xi$ is a possible configuration.\n",
    "\n",
    "Write your own MCMC algorithm from scratch to evaluate this expectation value for a grid of length 8.  You are limited to default python and the `numpy` package.\n",
    "\n",
    "In order to use an MCMC algorithm for this model, you must use a Markov chain whose state space is the set of all feasible configurations.  In order to have a stationary distribution, the Markov chain must be aperiodic and irreducible.  Such a Markov chain can be constructed by the following process.\n",
    "\n",
    "1. Start in a feasible configuration.\n",
    "\n",
    "2. For each integer time $t+1$:\n",
    "\n",
    "    1. Pick a vertex at random, uniformly \n",
    "    2. Toss a fair coin \n",
    "    3. If the coin is heads and all neighbors of the vertex is 0, set the vertex to 0. Set the vertex to 0 otherwise.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Why must we use MCMC for this problem?  Be specific about why we can't sample the state space exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
