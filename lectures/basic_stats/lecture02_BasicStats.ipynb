{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Statistics\n",
    "\n",
    "Karen Leighly Fall 2017\n",
    "\n",
    "Resources for this material:\n",
    "- Previous iteration of the Machine Learning class, specifically http://seminar.ouml.org/lectures/bayesian-statistics/\n",
    "- Jupyter notebook structure - Gordon Richards PHYS_T480 class (https://github.com/gtrichards/PHYS_T480)\n",
    "- Notes are taken from \"Introduction to Probability: Theory and Applications\" by R. L. Scheaffer and W. Mendenhall. This was the textbook for my undergraduate probability class; any undergraduate textbook should do.\n",
    "\n",
    "I will also be referring to University of Washington ASTR 324 (https://github.com/uw-astr-324-s17/astr-324-s17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Need for Probabilistic Thinking\n",
    "\n",
    "In science, nothing can be known absolutely.  All measurements have uncertainty, and all models have simplifying assumptions.  It is critical to think probabilistically, and to understand and be aware of assumptions, both explicit and implicit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combinatorics Review\n",
    "\n",
    "We will start with a review of probability and combinatorics, focusing on discrete data for today.  This lecture follows \"Introduction to Probability: Theory and Applications\" by Scheaffer & Mendenhall (hereafter abbreviated SM).\n",
    "\n",
    "#### Set Notation\n",
    "\n",
    "If the elements in the set are $a_1, a_2, a_3$, we generally write:  \n",
    "\n",
    "$A=\\{a_1, a_2, a_3\\}.$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Simple Set Relationships\n",
    "\n",
    "$A \\cup B$ is the <b>union</b> of sets A and B.  The result contains all of the elements in either set.\n",
    "\n",
    "$A \\cap B$ is the <b>intersection</b> of sets A and B.  The results contains all of the elements that appear in both sets.\n",
    "\n",
    "![Figure 3.1](http://www.astroml.org/_images/fig_prob_sum_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Distribution laws\n",
    "\n",
    "$A\\cap (B \\cup C) = (A \\cap B) \\cup (A\\cap C)$\n",
    "$A\\cup (B \\cap C) = (A\\cup B) \\cap (A \\cup C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The sample-point approach of computing probabilities\n",
    "\n",
    "Say you wanted to determine the probability of a discrete event.  The sample-point approach is the most straightforward method of determining the probability of an event.  (The sample-point approach is fundamental in frequentist statistics.)\n",
    "\n",
    "- List the simple possibilities of the experiment and check to see whether they can be further decomposed.\n",
    "- Assign probabilities to the sample points, making sure that the sum of the probability is 1.\n",
    "- Define the event of interest as a collection of the sample points (i.e., a subset of all possible points).\n",
    "- Find P(A) by summing the probabilities of the sample points in A.\n",
    "\n",
    "See SM Example 2.1 and 2.2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SM Example 2.1\n",
    "\n",
    "Cosider the problem of selecting two applicants for a job out of a group of five, and imagine that the applicants vary in competence, 1 being the best, 2 being the second best, and so on.  (These ratings are unknown to the employer.) Define two events, A and B:\n",
    "\n",
    " - A: The employer selects the best, and one of the two poorest applicants (i.e., applicants 1 and 4 or applicants 1 and 5)\n",
    " - B: The employer selects at least one of the two best. \n",
    " \n",
    "Find the probabilities for these two events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combinatorical Analysis\n",
    "\n",
    "Some elementary but useful results from the theory of combinatorics analysis.  \n",
    "\n",
    "**$mn$ rule:**  With $m$ elements in one set, and $n$ elements in another, it is possible to form $mn$ pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SM Example 2.3\n",
    "\n",
    "An experiment involves tossing a pair of dice and observing the results.  Find the number of points in $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Permutations\n",
    "\n",
    "$P^n_r = \\frac{n!}{(n-r)!}=n(n-1)(n-2)...(n-r+1)$ is the number of ways of ordering $n$ distinct objects taken $r$ at a time. \n",
    "\n",
    "Recall that factorial is defined as $n!=n(n-1)....(2)(1)$ and $0!=1$.  Note that this is for **ordered selection.**\n",
    "\n",
    "See SM Example 2.5, 2.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SM Example 2.5\n",
    "\n",
    "Opening a combination lock requires the selection of the correct set of four different digits in sequence.  How many combinations are there, assuming no digit is used twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Partitioning\n",
    "\n",
    "The number of ways of partitioning $n$ distinct objects into $k$ distinct groups containing $n_1, n_2, ..., n_k$ objects, respectively is:\n",
    "\n",
    "$N=\\frac{n!}{n_1!n_2!....n_k!} = \\binom{n}{n_1 n_2... n_k}$, where $\\sum_{i=1}^k n_i = n$.\n",
    "\n",
    "See SM Example 2.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SM Example 2.7\n",
    "\n",
    "A labor dispute has arisen concerning the alleged unequal distribution of 20 laborers to 4 different construction jobs.  The first job requires 6 laborers, the second, third and fourth required four, five and four respectively.  The dispose arose over an alleged random distribution of the laborers that placed all 4 members of a particular ethnic group on job 1 (considered to be the worst job).  \n",
    "\n",
    "If the assignment of the laborers to jobs was random, find the probability of the observed event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combinations\n",
    "\n",
    "The number of combinations of $n$ objects taken $r$ at a time is the number of ways of forming a subset of size $r$ from the $n$ objects. \n",
    "\n",
    "$C^n_r = \\binom{n}{r} = \\frac{P^n_r}{r!} = \\frac{n!}{r!(n-r)!}$\n",
    "\n",
    "Note that this subset is not ordered, unlike the permutations above.\n",
    "\n",
    "See SM Example 2.8, 2.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SM Example 2.8\n",
    "\n",
    "Find the number of ways of selecting two applicants out of 5, and hence the total number of sample points in $S$ for Example 2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Probability\n",
    "\n",
    "Conditional probability forms the heart of Bayesian analysis, since using Bayesian analysis allows us to take into account additional knowledge. For example, one might ask: what is the probability it will snow on a given day in Norman? That probability will change depending on the time of year, so the probability that it will snow given that it is December will be different than the probability it will snow given that it is August.\n",
    "\n",
    "$P(A|B) = \\frac{P(A\\cap B)}{P(B)}$ is the conditional probability of event A, given that an event B has occurred, provided $P(B)>0$. \n",
    "\n",
    "We read this as \"the probability of A given B (has occurred)\".  \n",
    "\n",
    "See SM Example 2.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SM Example 2.10\n",
    "Consider the toss of a single die. What is the probability that the result is 1, given the information that an odd number was obtained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Independent Events\n",
    "\n",
    "If $P(A\\cap B) = P(A)P(B)$ then the two events $A$ and $B$ are _independent_. Otherwise, if this is false, they are dependent. \n",
    "\n",
    "Then, if $A$ and $B$ are independent, $P(A|B)=P(A)$ and $P(B|A)=P(B)$.  \n",
    "\n",
    "I.e., the fact that $B$ has occurred has no influence on the conditional probability, because $A$ and $B$ are independent.\n",
    "\n",
    "See SM Example 2.11, 2.12\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SM Example 2.11\n",
    "\n",
    "Consider the toss of a single die, and 3 events:\n",
    " - A: Observe an odd number\n",
    " - B: Observe an even number\n",
    " - C: Observe a 1 or a 2\n",
    " \n",
    "(a.) Are A and B independent events?\n",
    "\n",
    "(b.) Are A and C independent events?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiplicative Law of Probability\n",
    "\n",
    "The probability of the intersection of two events, $A$ and $B$, is\n",
    "\n",
    "$$ P(A\\cap B) = P(A)P(B|A) = P(B)P(A|B).$$\n",
    "\n",
    "If $A$ and $B$ are independent, then\n",
    "\n",
    "$$P(A \\cap B) = P(A)P(B).$$\n",
    "\n",
    "Note it can be extended to any number of events:\n",
    "\n",
    "$$P(A\\cap B\\cap C) = P(A)P(B|A)P(C | A\\cap B).$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Additive Law of Probability\n",
    "\n",
    "The probability of the union of two events $A$ and $B$ is\n",
    "\n",
    "$$P(A \\cup B) = P(A)+P(B)-P(A\\cap B).$$\n",
    "\n",
    "If $A$ and $B$ are mutually exclusive events, $P (A \\cap B) = 0$ and\n",
    "$$P(A\\cup B) = P(A)+P(B).$$\n",
    "\n",
    "This can also be extended to any number of events:\n",
    "\n",
    "$$P(A\\cup B\\cup C) = P(A)+P(B)+P(C) - P(B\\cap C)$$\n",
    "$$-P(A\\cap B) - P(A\\cap C)+P(A\\cap B\\cap C).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Event-composition Method\n",
    "\n",
    "A useful approach for more complicated problems is to recast the event in question as a _composition_ (i.e., union and/or intersection) of two or more other events, and then use the multiplicative law of probability and / or the additive law of probability to solve for the probability of the event of interest.\n",
    "\n",
    "See SM examples 2.13-2.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SM Example 2.14\n",
    "\n",
    "Let's revisit the problem involving the selection of two applicants out of five, but instead of using the sample-point approach, we'll use the event-composition method.  Find the probability of drawing exactly one of the two best applicants, event $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complementary Events\n",
    "\n",
    "One very useful feature is that the probability that A is true plus the probability that A is not true must equal 1.  This can be useful if the probability of A not being true is easier to evaluate.  Mathematically:\n",
    "\n",
    "$P(A)=1-P(\\bar{A})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Rule\n",
    "\n",
    "Armed with these relationships, we are ready to derive Bayes' rule.  From the probability standpoint, the motivation for using Bayes' rule is that it is sometimes easier to solve probability problems if the sample space $S$ is viewed as the union of mutually exclusive subsets,\n",
    "i.e.,\n",
    "\n",
    "$$S=B_1\\cup B_2\\cup....\\cup B_k$$\n",
    "\n",
    "where $B_i\\cap B_j$ is the empty set for $i\\neq j$. Then, any subset A of S can be written as:\n",
    "\n",
    "$$A=A\\cap S$$\n",
    "$$=A\\cap (B_1 \\cup B_2 \\cup...\\cup B_k)$$\n",
    "$$= (A\\cap B_1) \\cup (A\\cap B_2) \\cup ...\\cup (A\\cap B_k)$$\n",
    "\n",
    "Then, using the additive rule of probability:\n",
    "\n",
    "$$P(A) = P(A\\cap B_1) + P(A\\cap B_2)+...+P(A\\cap B_k)$$\n",
    "\n",
    "Then, using the multiplicative rule of probability:\n",
    "\n",
    "$$ = P(B_1)P(A|B_1)+P(B_2)P(A|B_2)+....+P(B_k)P(A|B_k)$$\n",
    "$$ = \\sum_{i=1}^k P(B_i)P(A|B_i).$$\n",
    "\n",
    "Then, the probability of any $P(B_j|A)$ is (from conditional probability definition, and multiplicative law:\n",
    "\n",
    "$$P(B_j|A) = \\frac{P(A\\cap B_j)}{P(A)}$$\n",
    "\n",
    "$$=\\frac{P(B_j)P(A|B_j)}{\\sum_{i=1}^k P(B_i)P(A|B_i)}.$$\n",
    "\n",
    "The important part of the RHS is the numerator, because it can be understood that the probability will be normalized such that the integrated probability is equal to 1. So the denominator is often not evaluated explicitly.\n",
    "\n",
    "\n",
    "So for a single $B$ the equation becomes:\n",
    "\n",
    "$$P(B|A)=\\frac{P(A|B)P(B)}{P(A)} \\sim P(A|B)P(B).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will discuss Bayes' Rule in more detail the week after next.  But the terminology associated with it is important for understanding it, so we will mention that briefly here.\n",
    "\n",
    "$$P(B|A)=\\frac{P(A|B)P(B)}{P(A)} \\sim P(A|B)P(B).$$\n",
    "\n",
    " - $P(A|B)$ is known as the likelihood, and can be thought as the probability that the data that you have ($A$) matchs your model ($B$).\n",
    " - $P(B)$ is the prior, and it can be thought of as additional knowledge that you already have about the model.\n",
    " - $P(A)$ is the evidence, and as mentioned above, it is sometimes ignored because the posterior can be normalized _a posteriori_.\n",
    " - $P(B|A)$ is the posterior probability, can be though of as the probabiity of the model given the data, and is what you want.\n",
    " \n",
    "We can write this in words as:\n",
    "$${\\rm Posterior Probability} = \\frac{{\\rm Likelihood}\\times{\\rm Prior}}{{\\rm Evidence}},$$\n",
    "\n",
    "where we interpret the posterior probability as the probability of the model (including the model parameters).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Lego's \n",
    "\n",
    "An example with Lego's (it's awesome):\n",
    "[https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego](https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego)\n",
    "\n",
    "Also see SM Example 2.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Monty Hall Problem\n",
    "\n",
    "You are playing a game show and are shown 2 doors.  One has a car behind it, the other a goat.  What are your chances of picking the door with the car?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK, now there are 3 doors: one with a car, two with goats.  The game show host asks you to pick a door, but not to open it yet.  Then the host opens one of the other two doors (that you did not pick), making sure to select one with a goat.  The host offers you the opportunity to switch doors.  Do you?\n",
    "\n",
    "![https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/180px-Monty_open_door.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/180px-Monty_open_door.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now you are back at the 2 door situation.  But what can you make of your prior information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$p(1{\\rm st \\; choice}) = 1/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$p({\\rm other}) = 2/3$\n",
    "which doesn't change after host opens door without the prize.\n",
    "So, switching doubles your chances.  But only because you had prior information.  If someone walked in after the \"bad\" door was opened, then their probability of winning is the expected $1/2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For $N$ choices, revealing $N-2$ \"answers\" doesn't change the probability of your choice.  It is still $\\frac{1}{N}$.  But it *does* change the probability of your knowledge of the *other* remaining choice by $N-1$ and it is $\\frac{N-1}{N}$.\n",
    "\n",
    "This is an example of the use of *conditional* probability, where we have $p(A|B) \\ne p(A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Contingency Table\n",
    "\n",
    "We can also use Bayes' rule to learn something about false positives and false negatives.\n",
    "\n",
    "Let's say that we have a test for a disease.  The test can be positive ($T=1$) or negative ($T=0$) and one can either have the disease ($D=1$) or not ($D=0$).  So, there are 4 possible combinations:\n",
    "$$T=0; D=0 \\;\\;\\;  {\\rm true \\; negative}$$\n",
    "$$T=0; D=1 \\;\\;\\; {\\rm false \\; negative}$$\n",
    "$$T=1; D=0 \\;\\;\\; {\\rm false \\; positive}$$\n",
    "$$T=1; D=1 \\;\\;\\; {\\rm true \\; positive}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All else being equal, you have a 50% chance of being misdiagnosed.  Not good!  But the probability of disease and the accuracy of the test presumably are not random.\n",
    "\n",
    "If the rates of false positive and false negative are:\n",
    "$$p(T=1|D=0) = \\epsilon_{\\rm FP}$$\n",
    "$$p(T=0|D=1) = \\epsilon_{\\rm FN}$$\n",
    "\n",
    "then the true positive and true negative rates are just:\n",
    "$$p(T=0| D=0) = 1-\\epsilon_{\\rm FP}$$\n",
    "$$p(T=1| D=1) = 1-\\epsilon_{\\rm FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In graphical form this is:\n",
    "![http://www.astroml.org/_images/fig_contingency_table_1.png](http://www.astroml.org/_images/fig_contingency_table_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we have a **prior** regarding how likely the disease is, we can take this into account.\n",
    "\n",
    "$$p(D=1)=\\epsilon_D$$\n",
    "\n",
    "and then $p(D=0)=1-\\epsilon_D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bayes' rule then can be used to help us determine how likely it is that you have the disease if you tested positive:\n",
    "\n",
    "$$p(D=1|T=1) = \\frac{p(T=1|D=1)p(D=1)}{p(T=1)},$$\n",
    "\n",
    "where $$p(T=1) = p(T=1|D=0)p(D=0) + p(T=1|D=1)p(D=1).$$\n",
    "\n",
    "So\n",
    "$$p(D=1|T=1) = \\frac{(1 - \\epsilon_{FN})\\epsilon_D}{\\epsilon_{FP}(1-\\epsilon_D) + (1-\\epsilon_{FN})\\epsilon_D} \\approx \\frac{\\epsilon_D}{\\epsilon_D+\\epsilon_{FP}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Wondering why we can't just read $p(D=1|T=1)$ off the table?  That because the table entry is the conditional probability of the *test* given the *data*, $p(T=1|D=1)$, what we want is the conditional probability of the *data* given the *test*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That means that to get a reliable diagnosis, we need $\\epsilon_{FP}$ to be quite small.  (Because you *want* the probability to be close to unity if you test positive, otherwise it is a *false* positive).\n",
    "\n",
    "Take an example with a disease rate of 1% and a false positive rate of 2%.  \n",
    "\n",
    "So we have\n",
    "$$p(D=1|T=1) = \\frac{0.01}{0.01+0.02} = 0.333$$\n",
    "\n",
    "Then in a sample of 1000 people, 10 people will *actually* have the disease $(1000*0.01)$, but another 20 $(1000*0.02)$ will test positive!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
